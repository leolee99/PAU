2023-12-22 21:18:31,717:INFO: Effective parameters:
2023-12-22 21:18:31,718:INFO:   <<< K: 8
2023-12-22 21:18:31,718:INFO:   <<< batch_size: 32
2023-12-22 21:18:31,718:INFO:   <<< batch_size_val: 24
2023-12-22 21:18:31,718:INFO:   <<< cache_dir: 
2023-12-22 21:18:31,718:INFO:   <<< coef_lr: 0.001
2023-12-22 21:18:31,718:INFO:   <<< cross_model: cross-base
2023-12-22 21:18:31,718:INFO:   <<< cross_num_hidden_layers: 4
2023-12-22 21:18:31,718:INFO:   <<< data_path: ../data/VR_Dataset/DiDeMo/annotation
2023-12-22 21:18:31,718:INFO:   <<< datatype: didemo
2023-12-22 21:18:31,719:INFO:   <<< do_eval: True
2023-12-22 21:18:31,719:INFO:   <<< do_lower_case: False
2023-12-22 21:18:31,719:INFO:   <<< do_pretrain: False
2023-12-22 21:18:31,719:INFO:   <<< do_train: False
2023-12-22 21:18:31,719:INFO:   <<< epochs: 20
2023-12-22 21:18:31,719:INFO:   <<< eval_frame_order: 0
2023-12-22 21:18:31,719:INFO:   <<< expand_msrvtt_sentences: False
2023-12-22 21:18:31,719:INFO:   <<< feature_framerate: 1
2023-12-22 21:18:31,719:INFO:   <<< features_path: ../data/VR_Dataset/DiDeMo/video
2023-12-22 21:18:31,719:INFO:   <<< fp16: False
2023-12-22 21:18:31,719:INFO:   <<< fp16_opt_level: O1
2023-12-22 21:18:31,719:INFO:   <<< freeze_layer_num: 0
2023-12-22 21:18:31,719:INFO:   <<< gradient_accumulation_steps: 1
2023-12-22 21:18:31,719:INFO:   <<< hard_negative_rate: 0.5
2023-12-22 21:18:31,719:INFO:   <<< init_model: log/DiDeMo-pytorch_model.bin.0
2023-12-22 21:18:31,720:INFO:   <<< lambda1: 1.0
2023-12-22 21:18:31,720:INFO:   <<< lambda2: 100.0
2023-12-22 21:18:31,720:INFO:   <<< lambda3: 0.025
2023-12-22 21:18:31,720:INFO:   <<< linear_patch: 2d
2023-12-22 21:18:31,720:INFO:   <<< local_rank: 0
2023-12-22 21:18:31,720:INFO:   <<< loose_type: True
2023-12-22 21:18:31,720:INFO:   <<< lr: 0.0001
2023-12-22 21:18:31,720:INFO:   <<< lr_decay: 0.9
2023-12-22 21:18:31,720:INFO:   <<< margin: 0.1
2023-12-22 21:18:31,720:INFO:   <<< max_frames: 64
2023-12-22 21:18:31,720:INFO:   <<< max_words: 64
2023-12-22 21:18:31,720:INFO:   <<< n_display: 10
2023-12-22 21:18:31,720:INFO:   <<< n_gpu: 1
2023-12-22 21:18:31,720:INFO:   <<< n_pair: 1
2023-12-22 21:18:31,720:INFO:   <<< negative_weighting: 1
2023-12-22 21:18:31,720:INFO:   <<< num_thread_reader: 8
2023-12-22 21:18:31,720:INFO:   <<< output_dir: log
2023-12-22 21:18:31,721:INFO:   <<< precision: fp16
2023-12-22 21:18:31,721:INFO:   <<< pretrained_clip_name: ViT-B/32
2023-12-22 21:18:31,721:INFO:   <<< rank: 0
2023-12-22 21:18:31,721:INFO:   <<< rerank_coe_t: 0.05
2023-12-22 21:18:31,721:INFO:   <<< rerank_coe_v: 0.05
2023-12-22 21:18:31,721:INFO:   <<< resume_opt: None
2023-12-22 21:18:31,721:INFO:   <<< sampled_use_mil: False
2023-12-22 21:18:31,721:INFO:   <<< seed: 42
2023-12-22 21:18:31,721:INFO:   <<< sim_header: seqTransf
2023-12-22 21:18:31,721:INFO:   <<< slice_framepos: 2
2023-12-22 21:18:31,721:INFO:   <<< task_type: retrieval
2023-12-22 21:18:31,721:INFO:   <<< tau: 5
2023-12-22 21:18:31,721:INFO:   <<< text_num_hidden_layers: 12
2023-12-22 21:18:31,721:INFO:   <<< train_csv: data/.train.csv
2023-12-22 21:18:31,721:INFO:   <<< train_frame_order: 0
2023-12-22 21:18:31,721:INFO:   <<< use_mil: False
2023-12-22 21:18:31,722:INFO:   <<< val_csv: data/.val.csv
2023-12-22 21:18:31,722:INFO:   <<< video_dim: 1024
2023-12-22 21:18:31,722:INFO:   <<< visual_num_hidden_layers: 12
2023-12-22 21:18:31,722:INFO:   <<< warmup_proportion: 0.1
2023-12-22 21:18:31,722:INFO:   <<< world_size: 1
2023-12-22 21:18:31,723:INFO: device: cuda:0 n_gpu: 1
2023-12-22 21:18:35,416:INFO: loading archive file /home/lihao/PAU/modules/cross-base
2023-12-22 21:18:35,417:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2023-12-22 21:18:35,417:INFO: Weight doesn't exsits. /home/lihao/PAU/modules/cross-base/cross_pytorch_model.bin
2023-12-22 21:18:35,418:WARNING: Stage-One:True, Stage-Two:False
2023-12-22 21:18:35,418:WARNING: Test retrieval by loose type.
2023-12-22 21:18:35,418:WARNING: 	 embed_dim: 512
2023-12-22 21:18:35,418:WARNING: 	 image_resolution: 224
2023-12-22 21:18:35,418:WARNING: 	 vision_layers: 12
2023-12-22 21:18:35,418:WARNING: 	 vision_width: 768
2023-12-22 21:18:35,418:WARNING: 	 vision_patch_size: 32
2023-12-22 21:18:35,418:WARNING: 	 context_length: 77
2023-12-22 21:18:35,418:WARNING: 	 vocab_size: 49408
2023-12-22 21:18:35,418:WARNING: 	 transformer_width: 512
2023-12-22 21:18:35,418:WARNING: 	 transformer_heads: 8
2023-12-22 21:18:35,418:WARNING: 	 transformer_layers: 12
2023-12-22 21:18:35,418:WARNING: 		 linear_patch: 2d
2023-12-22 21:18:35,418:WARNING: 	 cut_top_layer: 0
2023-12-22 21:18:38,328:WARNING: 	 sim_header: seqTransf
2023-12-22 21:18:47,521:INFO: --------------------
2023-12-22 21:18:47,521:INFO: Weights of PAU not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
2023-12-22 21:18:47,521:INFO: Weights from pretrained model not used in PAU: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2023-12-22 21:18:48,624:INFO: ***** Running test *****
2023-12-22 21:18:48,624:INFO:   Num examples = 824
2023-12-22 21:18:48,624:INFO:   Batch size = 24
2023-12-22 21:18:48,624:INFO:   Num steps = 35
2023-12-22 21:18:48,624:INFO: ***** Running val *****
2023-12-22 21:18:48,624:INFO:   Num examples = 842
2023-12-22 21:19:32,715:INFO: Effective parameters:
2023-12-22 21:19:32,715:INFO:   <<< K: 8
2023-12-22 21:19:32,715:INFO:   <<< batch_size: 32
2023-12-22 21:19:32,715:INFO:   <<< batch_size_val: 24
2023-12-22 21:19:32,715:INFO:   <<< cache_dir: 
2023-12-22 21:19:32,715:INFO:   <<< coef_lr: 0.001
2023-12-22 21:19:32,715:INFO:   <<< cross_model: cross-base
2023-12-22 21:19:32,715:INFO:   <<< cross_num_hidden_layers: 4
2023-12-22 21:19:32,715:INFO:   <<< data_path: ../data/VR_Dataset/DiDeMo/annotation
2023-12-22 21:19:32,715:INFO:   <<< datatype: didemo
2023-12-22 21:19:32,715:INFO:   <<< do_eval: True
2023-12-22 21:19:32,715:INFO:   <<< do_lower_case: False
2023-12-22 21:19:32,715:INFO:   <<< do_pretrain: False
2023-12-22 21:19:32,715:INFO:   <<< do_train: False
2023-12-22 21:19:32,715:INFO:   <<< epochs: 20
2023-12-22 21:19:32,715:INFO:   <<< eval_frame_order: 0
2023-12-22 21:19:32,715:INFO:   <<< expand_msrvtt_sentences: False
2023-12-22 21:19:32,715:INFO:   <<< feature_framerate: 1
2023-12-22 21:19:32,715:INFO:   <<< features_path: ../data/VR_Dataset/DiDeMo/video
2023-12-22 21:19:32,715:INFO:   <<< fp16: False
2023-12-22 21:19:32,715:INFO:   <<< fp16_opt_level: O1
2023-12-22 21:19:32,715:INFO:   <<< freeze_layer_num: 0
2023-12-22 21:19:32,715:INFO:   <<< gradient_accumulation_steps: 1
2023-12-22 21:19:32,716:INFO:   <<< hard_negative_rate: 0.5
2023-12-22 21:19:32,716:INFO:   <<< init_model: log/DiDeMo-pytorch_model.bin.0
2023-12-22 21:19:32,716:INFO:   <<< lambda1: 1.0
2023-12-22 21:19:32,716:INFO:   <<< lambda2: 100.0
2023-12-22 21:19:32,716:INFO:   <<< lambda3: 0.025
2023-12-22 21:19:32,716:INFO:   <<< linear_patch: 2d
2023-12-22 21:19:32,716:INFO:   <<< local_rank: 0
2023-12-22 21:19:32,716:INFO:   <<< loose_type: True
2023-12-22 21:19:32,716:INFO:   <<< lr: 0.0001
2023-12-22 21:19:32,716:INFO:   <<< lr_decay: 0.9
2023-12-22 21:19:32,716:INFO:   <<< margin: 0.1
2023-12-22 21:19:32,716:INFO:   <<< max_frames: 64
2023-12-22 21:19:32,716:INFO:   <<< max_words: 64
2023-12-22 21:19:32,716:INFO:   <<< n_display: 10
2023-12-22 21:19:32,716:INFO:   <<< n_gpu: 1
2023-12-22 21:19:32,716:INFO:   <<< n_pair: 1
2023-12-22 21:19:32,716:INFO:   <<< negative_weighting: 1
2023-12-22 21:19:32,716:INFO:   <<< num_thread_reader: 8
2023-12-22 21:19:32,716:INFO:   <<< output_dir: log
2023-12-22 21:19:32,716:INFO:   <<< precision: fp16
2023-12-22 21:19:32,716:INFO:   <<< pretrained_clip_name: ViT-B/32
2023-12-22 21:19:32,716:INFO:   <<< rank: 0
2023-12-22 21:19:32,716:INFO:   <<< rerank_coe_t: 0.05
2023-12-22 21:19:32,716:INFO:   <<< rerank_coe_v: 0.05
2023-12-22 21:19:32,716:INFO:   <<< resume_opt: None
2023-12-22 21:19:32,716:INFO:   <<< sampled_use_mil: False
2023-12-22 21:19:32,716:INFO:   <<< seed: 42
2023-12-22 21:19:32,716:INFO:   <<< sim_header: seqTransf
2023-12-22 21:19:32,716:INFO:   <<< slice_framepos: 2
2023-12-22 21:19:32,716:INFO:   <<< task_type: retrieval
2023-12-22 21:19:32,716:INFO:   <<< tau: 5
2023-12-22 21:19:32,716:INFO:   <<< text_num_hidden_layers: 12
2023-12-22 21:19:32,716:INFO:   <<< train_csv: data/.train.csv
2023-12-22 21:19:32,716:INFO:   <<< train_frame_order: 0
2023-12-22 21:19:32,716:INFO:   <<< use_mil: False
2023-12-22 21:19:32,716:INFO:   <<< val_csv: data/.val.csv
2023-12-22 21:19:32,716:INFO:   <<< video_dim: 1024
2023-12-22 21:19:32,716:INFO:   <<< visual_num_hidden_layers: 12
2023-12-22 21:19:32,716:INFO:   <<< warmup_proportion: 0.1
2023-12-22 21:19:32,717:INFO:   <<< world_size: 1
2023-12-22 21:19:32,717:INFO: device: cuda:0 n_gpu: 1
2023-12-22 21:19:34,655:INFO: loading archive file /home/lihao/PAU/modules/cross-base
2023-12-22 21:19:34,656:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2023-12-22 21:19:34,656:INFO: Weight doesn't exsits. /home/lihao/PAU/modules/cross-base/cross_pytorch_model.bin
2023-12-22 21:19:34,656:WARNING: Stage-One:True, Stage-Two:False
2023-12-22 21:19:34,656:WARNING: Test retrieval by loose type.
2023-12-22 21:19:34,656:WARNING: 	 embed_dim: 512
2023-12-22 21:19:34,656:WARNING: 	 image_resolution: 224
2023-12-22 21:19:34,656:WARNING: 	 vision_layers: 12
2023-12-22 21:19:34,656:WARNING: 	 vision_width: 768
2023-12-22 21:19:34,656:WARNING: 	 vision_patch_size: 32
2023-12-22 21:19:34,657:WARNING: 	 context_length: 77
2023-12-22 21:19:34,657:WARNING: 	 vocab_size: 49408
2023-12-22 21:19:34,657:WARNING: 	 transformer_width: 512
2023-12-22 21:19:34,657:WARNING: 	 transformer_heads: 8
2023-12-22 21:19:34,657:WARNING: 	 transformer_layers: 12
2023-12-22 21:19:34,657:WARNING: 		 linear_patch: 2d
2023-12-22 21:19:34,657:WARNING: 	 cut_top_layer: 0
2023-12-22 21:19:36,240:WARNING: 	 sim_header: seqTransf
2023-12-22 21:19:42,927:INFO: --------------------
2023-12-22 21:19:42,927:INFO: Weights of PAU not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
2023-12-22 21:19:42,927:INFO: Weights from pretrained model not used in PAU: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2023-12-22 21:19:43,621:INFO: ***** Running test *****
2023-12-22 21:19:43,621:INFO:   Num examples = 824
2023-12-22 21:19:43,621:INFO:   Batch size = 24
2023-12-22 21:19:43,622:INFO:   Num steps = 35
2023-12-22 21:19:43,622:INFO: ***** Running val *****
2023-12-22 21:19:43,622:INFO:   Num examples = 842
2023-12-22 21:24:23,654:INFO: sim matrix size: 824, 824
2023-12-22 21:24:23,694:INFO: 	 Length-T: 824, Length-V:824
2023-12-22 21:24:23,694:INFO: Text-to-Video:
2023-12-22 21:24:23,695:INFO: 	>>>  R@1: 47.6 - R@5: 76.3 - R@10: 83.9 - Median R: 2.0 - Mean R: 12.7
2023-12-22 21:24:23,695:INFO: Video-to-Text:
2023-12-22 21:24:23,695:INFO: 	>>>  V2T$R@1: 47.9 - V2T$R@5: 74.2 - V2T$R@10: 85.3 - V2T$Median R: 2.0 - V2T$Mean R: 9.9
2023-12-22 21:26:16,820:INFO: Effective parameters:
2023-12-22 21:26:16,820:INFO:   <<< K: 8
2023-12-22 21:26:16,821:INFO:   <<< batch_size: 32
2023-12-22 21:26:16,821:INFO:   <<< batch_size_val: 24
2023-12-22 21:26:16,821:INFO:   <<< cache_dir: 
2023-12-22 21:26:16,821:INFO:   <<< coef_lr: 0.001
2023-12-22 21:26:16,821:INFO:   <<< cross_model: cross-base
2023-12-22 21:26:16,821:INFO:   <<< cross_num_hidden_layers: 4
2023-12-22 21:26:16,821:INFO:   <<< data_path: ../data/VR_Dataset/DiDeMo/annotation
2023-12-22 21:26:16,821:INFO:   <<< datatype: didemo
2023-12-22 21:26:16,821:INFO:   <<< do_eval: True
2023-12-22 21:26:16,821:INFO:   <<< do_lower_case: False
2023-12-22 21:26:16,821:INFO:   <<< do_pretrain: False
2023-12-22 21:26:16,821:INFO:   <<< do_train: False
2023-12-22 21:26:16,821:INFO:   <<< epochs: 20
2023-12-22 21:26:16,821:INFO:   <<< eval_frame_order: 0
2023-12-22 21:26:16,821:INFO:   <<< expand_msrvtt_sentences: False
2023-12-22 21:26:16,821:INFO:   <<< feature_framerate: 1
2023-12-22 21:26:16,821:INFO:   <<< features_path: ../data/VR_Dataset/DiDeMo/video
2023-12-22 21:26:16,821:INFO:   <<< fp16: False
2023-12-22 21:26:16,821:INFO:   <<< fp16_opt_level: O1
2023-12-22 21:26:16,821:INFO:   <<< freeze_layer_num: 0
2023-12-22 21:26:16,821:INFO:   <<< gradient_accumulation_steps: 1
2023-12-22 21:26:16,821:INFO:   <<< hard_negative_rate: 0.5
2023-12-22 21:26:16,821:INFO:   <<< init_model: log/DiDeMo-pytorch_model.bin.0
2023-12-22 21:26:16,821:INFO:   <<< lambda1: 1.0
2023-12-22 21:26:16,821:INFO:   <<< lambda2: 100.0
2023-12-22 21:26:16,821:INFO:   <<< lambda3: 0.025
2023-12-22 21:26:16,821:INFO:   <<< linear_patch: 2d
2023-12-22 21:26:16,821:INFO:   <<< local_rank: 0
2023-12-22 21:26:16,821:INFO:   <<< loose_type: True
2023-12-22 21:26:16,822:INFO:   <<< lr: 0.0001
2023-12-22 21:26:16,822:INFO:   <<< lr_decay: 0.9
2023-12-22 21:26:16,822:INFO:   <<< margin: 0.1
2023-12-22 21:26:16,822:INFO:   <<< max_frames: 64
2023-12-22 21:26:16,822:INFO:   <<< max_words: 64
2023-12-22 21:26:16,822:INFO:   <<< n_display: 10
2023-12-22 21:26:16,822:INFO:   <<< n_gpu: 1
2023-12-22 21:26:16,822:INFO:   <<< n_pair: 1
2023-12-22 21:26:16,822:INFO:   <<< negative_weighting: 1
2023-12-22 21:26:16,822:INFO:   <<< num_thread_reader: 8
2023-12-22 21:26:16,822:INFO:   <<< output_dir: log
2023-12-22 21:26:16,822:INFO:   <<< precision: fp16
2023-12-22 21:26:16,822:INFO:   <<< pretrained_clip_name: ViT-B/32
2023-12-22 21:26:16,822:INFO:   <<< rank: 0
2023-12-22 21:26:16,822:INFO:   <<< rerank_coe_t: 0.5
2023-12-22 21:26:16,822:INFO:   <<< rerank_coe_v: 0.5
2023-12-22 21:26:16,822:INFO:   <<< resume_opt: None
2023-12-22 21:26:16,822:INFO:   <<< sampled_use_mil: False
2023-12-22 21:26:16,822:INFO:   <<< seed: 42
2023-12-22 21:26:16,822:INFO:   <<< sim_header: seqTransf
2023-12-22 21:26:16,822:INFO:   <<< slice_framepos: 2
2023-12-22 21:26:16,822:INFO:   <<< task_type: retrieval
2023-12-22 21:26:16,822:INFO:   <<< tau: 5
2023-12-22 21:26:16,823:INFO:   <<< text_num_hidden_layers: 12
2023-12-22 21:26:16,823:INFO:   <<< train_csv: data/.train.csv
2023-12-22 21:26:16,823:INFO:   <<< train_frame_order: 0
2023-12-22 21:26:16,823:INFO:   <<< use_mil: False
2023-12-22 21:26:16,823:INFO:   <<< val_csv: data/.val.csv
2023-12-22 21:26:16,823:INFO:   <<< video_dim: 1024
2023-12-22 21:26:16,823:INFO:   <<< visual_num_hidden_layers: 12
2023-12-22 21:26:16,823:INFO:   <<< warmup_proportion: 0.1
2023-12-22 21:26:16,823:INFO:   <<< world_size: 1
2023-12-22 21:26:16,823:INFO: device: cuda:0 n_gpu: 1
2023-12-22 21:26:19,406:INFO: loading archive file /home/lihao/PAU/modules/cross-base
2023-12-22 21:26:19,407:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2023-12-22 21:26:19,407:INFO: Weight doesn't exsits. /home/lihao/PAU/modules/cross-base/cross_pytorch_model.bin
2023-12-22 21:26:19,408:WARNING: Stage-One:True, Stage-Two:False
2023-12-22 21:26:19,408:WARNING: Test retrieval by loose type.
2023-12-22 21:26:19,408:WARNING: 	 embed_dim: 512
2023-12-22 21:26:19,408:WARNING: 	 image_resolution: 224
2023-12-22 21:26:19,408:WARNING: 	 vision_layers: 12
2023-12-22 21:26:19,408:WARNING: 	 vision_width: 768
2023-12-22 21:26:19,408:WARNING: 	 vision_patch_size: 32
2023-12-22 21:26:19,408:WARNING: 	 context_length: 77
2023-12-22 21:26:19,408:WARNING: 	 vocab_size: 49408
2023-12-22 21:26:19,408:WARNING: 	 transformer_width: 512
2023-12-22 21:26:19,408:WARNING: 	 transformer_heads: 8
2023-12-22 21:26:19,408:WARNING: 	 transformer_layers: 12
2023-12-22 21:26:19,409:WARNING: 		 linear_patch: 2d
2023-12-22 21:26:19,409:WARNING: 	 cut_top_layer: 0
2023-12-22 21:26:21,600:WARNING: 	 sim_header: seqTransf
2023-12-22 21:26:30,729:INFO: --------------------
2023-12-22 21:26:30,729:INFO: Weights of PAU not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
2023-12-22 21:26:30,729:INFO: Weights from pretrained model not used in PAU: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2023-12-22 21:26:31,708:INFO: ***** Running test *****
2023-12-22 21:26:31,708:INFO:   Num examples = 824
2023-12-22 21:26:31,708:INFO:   Batch size = 24
2023-12-22 21:26:31,708:INFO:   Num steps = 35
2023-12-22 21:26:31,708:INFO: ***** Running val *****
2023-12-22 21:26:31,708:INFO:   Num examples = 842
2023-12-22 21:31:04,198:INFO: sim matrix size: 824, 824
2023-12-22 21:31:04,220:INFO: 	 Length-T: 824, Length-V:824
2023-12-22 21:31:04,220:INFO: Text-to-Video:
2023-12-22 21:31:04,220:INFO: 	>>>  R@1: 47.6 - R@5: 76.3 - R@10: 84.0 - Median R: 2.0 - Mean R: 12.7
2023-12-22 21:31:04,220:INFO: Video-to-Text:
2023-12-22 21:31:04,220:INFO: 	>>>  V2T$R@1: 47.9 - V2T$R@5: 74.3 - V2T$R@10: 85.3 - V2T$Median R: 2.0 - V2T$Mean R: 9.8
2023-12-22 21:31:31,180:INFO: Effective parameters:
2023-12-22 21:31:31,180:INFO:   <<< K: 8
2023-12-22 21:31:31,180:INFO:   <<< batch_size: 32
2023-12-22 21:31:31,180:INFO:   <<< batch_size_val: 24
2023-12-22 21:31:31,180:INFO:   <<< cache_dir: 
2023-12-22 21:31:31,180:INFO:   <<< coef_lr: 0.001
2023-12-22 21:31:31,180:INFO:   <<< cross_model: cross-base
2023-12-22 21:31:31,180:INFO:   <<< cross_num_hidden_layers: 4
2023-12-22 21:31:31,180:INFO:   <<< data_path: ../data/VR_Dataset/DiDeMo/annotation
2023-12-22 21:31:31,180:INFO:   <<< datatype: didemo
2023-12-22 21:31:31,180:INFO:   <<< do_eval: True
2023-12-22 21:31:31,180:INFO:   <<< do_lower_case: False
2023-12-22 21:31:31,180:INFO:   <<< do_pretrain: False
2023-12-22 21:31:31,180:INFO:   <<< do_train: False
2023-12-22 21:31:31,180:INFO:   <<< epochs: 20
2023-12-22 21:31:31,181:INFO:   <<< eval_frame_order: 0
2023-12-22 21:31:31,181:INFO:   <<< expand_msrvtt_sentences: False
2023-12-22 21:31:31,181:INFO:   <<< feature_framerate: 1
2023-12-22 21:31:31,181:INFO:   <<< features_path: ../data/VR_Dataset/DiDeMo/video
2023-12-22 21:31:31,181:INFO:   <<< fp16: False
2023-12-22 21:31:31,181:INFO:   <<< fp16_opt_level: O1
2023-12-22 21:31:31,181:INFO:   <<< freeze_layer_num: 0
2023-12-22 21:31:31,181:INFO:   <<< gradient_accumulation_steps: 1
2023-12-22 21:31:31,181:INFO:   <<< hard_negative_rate: 0.5
2023-12-22 21:31:31,181:INFO:   <<< init_model: log/DiDeMo-pytorch_model.bin.0
2023-12-22 21:31:31,181:INFO:   <<< lambda1: 1.0
2023-12-22 21:31:31,181:INFO:   <<< lambda2: 100.0
2023-12-22 21:31:31,181:INFO:   <<< lambda3: 0.025
2023-12-22 21:31:31,181:INFO:   <<< linear_patch: 2d
2023-12-22 21:31:31,181:INFO:   <<< local_rank: 0
2023-12-22 21:31:31,181:INFO:   <<< loose_type: True
2023-12-22 21:31:31,181:INFO:   <<< lr: 0.0001
2023-12-22 21:31:31,181:INFO:   <<< lr_decay: 0.9
2023-12-22 21:31:31,181:INFO:   <<< margin: 0.1
2023-12-22 21:31:31,181:INFO:   <<< max_frames: 64
2023-12-22 21:31:31,181:INFO:   <<< max_words: 64
2023-12-22 21:31:31,181:INFO:   <<< n_display: 10
2023-12-22 21:31:31,181:INFO:   <<< n_gpu: 1
2023-12-22 21:31:31,181:INFO:   <<< n_pair: 1
2023-12-22 21:31:31,181:INFO:   <<< negative_weighting: 1
2023-12-22 21:31:31,181:INFO:   <<< num_thread_reader: 8
2023-12-22 21:31:31,181:INFO:   <<< output_dir: log
2023-12-22 21:31:31,181:INFO:   <<< precision: fp16
2023-12-22 21:31:31,181:INFO:   <<< pretrained_clip_name: ViT-B/32
2023-12-22 21:31:31,182:INFO:   <<< rank: 0
2023-12-22 21:31:31,182:INFO:   <<< rerank_coe_t: 1.0
2023-12-22 21:31:31,182:INFO:   <<< rerank_coe_v: 4.5
2023-12-22 21:31:31,182:INFO:   <<< resume_opt: None
2023-12-22 21:31:31,182:INFO:   <<< sampled_use_mil: False
2023-12-22 21:31:31,182:INFO:   <<< seed: 42
2023-12-22 21:31:31,182:INFO:   <<< sim_header: seqTransf
2023-12-22 21:31:31,182:INFO:   <<< slice_framepos: 2
2023-12-22 21:31:31,182:INFO:   <<< task_type: retrieval
2023-12-22 21:31:31,182:INFO:   <<< tau: 5
2023-12-22 21:31:31,182:INFO:   <<< text_num_hidden_layers: 12
2023-12-22 21:31:31,182:INFO:   <<< train_csv: data/.train.csv
2023-12-22 21:31:31,182:INFO:   <<< train_frame_order: 0
2023-12-22 21:31:31,182:INFO:   <<< use_mil: False
2023-12-22 21:31:31,182:INFO:   <<< val_csv: data/.val.csv
2023-12-22 21:31:31,182:INFO:   <<< video_dim: 1024
2023-12-22 21:31:31,182:INFO:   <<< visual_num_hidden_layers: 12
2023-12-22 21:31:31,182:INFO:   <<< warmup_proportion: 0.1
2023-12-22 21:31:31,182:INFO:   <<< world_size: 1
2023-12-22 21:31:31,183:INFO: device: cuda:0 n_gpu: 1
2023-12-22 21:31:33,799:INFO: loading archive file /home/lihao/PAU/modules/cross-base
2023-12-22 21:31:33,800:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2023-12-22 21:31:33,800:INFO: Weight doesn't exsits. /home/lihao/PAU/modules/cross-base/cross_pytorch_model.bin
2023-12-22 21:31:33,800:WARNING: Stage-One:True, Stage-Two:False
2023-12-22 21:31:33,800:WARNING: Test retrieval by loose type.
2023-12-22 21:31:33,800:WARNING: 	 embed_dim: 512
2023-12-22 21:31:33,800:WARNING: 	 image_resolution: 224
2023-12-22 21:31:33,800:WARNING: 	 vision_layers: 12
2023-12-22 21:31:33,800:WARNING: 	 vision_width: 768
2023-12-22 21:31:33,801:WARNING: 	 vision_patch_size: 32
2023-12-22 21:31:33,801:WARNING: 	 context_length: 77
2023-12-22 21:31:33,801:WARNING: 	 vocab_size: 49408
2023-12-22 21:31:33,801:WARNING: 	 transformer_width: 512
2023-12-22 21:31:33,801:WARNING: 	 transformer_heads: 8
2023-12-22 21:31:33,801:WARNING: 	 transformer_layers: 12
2023-12-22 21:31:33,801:WARNING: 		 linear_patch: 2d
2023-12-22 21:31:33,801:WARNING: 	 cut_top_layer: 0
2023-12-22 21:31:36,287:WARNING: 	 sim_header: seqTransf
2023-12-22 21:31:45,692:INFO: --------------------
2023-12-22 21:31:45,692:INFO: Weights of PAU not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
2023-12-22 21:31:45,692:INFO: Weights from pretrained model not used in PAU: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2023-12-22 21:31:46,623:INFO: ***** Running test *****
2023-12-22 21:31:46,623:INFO:   Num examples = 824
2023-12-22 21:31:46,623:INFO:   Batch size = 24
2023-12-22 21:31:46,624:INFO:   Num steps = 35
2023-12-22 21:31:46,624:INFO: ***** Running val *****
2023-12-22 21:31:46,624:INFO:   Num examples = 842
2023-12-22 21:36:38,514:INFO: sim matrix size: 824, 824
2023-12-22 21:36:38,535:INFO: 	 Length-T: 824, Length-V:824
2023-12-22 21:36:38,535:INFO: Text-to-Video:
2023-12-22 21:36:38,535:INFO: 	>>>  R@1: 48.6 - R@5: 76.0 - R@10: 84.5 - Median R: 2.0 - Mean R: 12.9
2023-12-22 21:36:38,535:INFO: Video-to-Text:
2023-12-22 21:36:38,535:INFO: 	>>>  V2T$R@1: 48.1 - V2T$R@5: 74.2 - V2T$R@10: 85.7 - V2T$Median R: 2.0 - V2T$Mean R: 9.8
2023-12-22 21:37:22,929:INFO: Effective parameters:
2023-12-22 21:37:22,929:INFO:   <<< K: 8
2023-12-22 21:37:22,929:INFO:   <<< batch_size: 32
2023-12-22 21:37:22,929:INFO:   <<< batch_size_val: 24
2023-12-22 21:37:22,929:INFO:   <<< cache_dir: 
2023-12-22 21:37:22,929:INFO:   <<< coef_lr: 0.001
2023-12-22 21:37:22,929:INFO:   <<< cross_model: cross-base
2023-12-22 21:37:22,929:INFO:   <<< cross_num_hidden_layers: 4
2023-12-22 21:37:22,929:INFO:   <<< data_path: ../data/VR_Dataset/DiDeMo/annotation
2023-12-22 21:37:22,929:INFO:   <<< datatype: didemo
2023-12-22 21:37:22,929:INFO:   <<< do_eval: True
2023-12-22 21:37:22,929:INFO:   <<< do_lower_case: False
2023-12-22 21:37:22,929:INFO:   <<< do_pretrain: False
2023-12-22 21:37:22,929:INFO:   <<< do_train: False
2023-12-22 21:37:22,929:INFO:   <<< epochs: 20
2023-12-22 21:37:22,929:INFO:   <<< eval_frame_order: 0
2023-12-22 21:37:22,929:INFO:   <<< expand_msrvtt_sentences: False
2023-12-22 21:37:22,929:INFO:   <<< feature_framerate: 1
2023-12-22 21:37:22,930:INFO:   <<< features_path: ../data/VR_Dataset/DiDeMo/video
2023-12-22 21:37:22,930:INFO:   <<< fp16: False
2023-12-22 21:37:22,930:INFO:   <<< fp16_opt_level: O1
2023-12-22 21:37:22,930:INFO:   <<< freeze_layer_num: 0
2023-12-22 21:37:22,930:INFO:   <<< gradient_accumulation_steps: 1
2023-12-22 21:37:22,930:INFO:   <<< hard_negative_rate: 0.5
2023-12-22 21:37:22,930:INFO:   <<< init_model: log/DiDeMo-pytorch_model.bin.0
2023-12-22 21:37:22,930:INFO:   <<< lambda1: 1
2023-12-22 21:37:22,930:INFO:   <<< lambda2: 100
2023-12-22 21:37:22,930:INFO:   <<< lambda3: 0.025
2023-12-22 21:37:22,930:INFO:   <<< linear_patch: 2d
2023-12-22 21:37:22,930:INFO:   <<< local_rank: 0
2023-12-22 21:37:22,930:INFO:   <<< loose_type: True
2023-12-22 21:37:22,930:INFO:   <<< lr: 0.0001
2023-12-22 21:37:22,930:INFO:   <<< lr_decay: 0.9
2023-12-22 21:37:22,930:INFO:   <<< margin: 0.1
2023-12-22 21:37:22,930:INFO:   <<< max_frames: 64
2023-12-22 21:37:22,930:INFO:   <<< max_words: 64
2023-12-22 21:37:22,930:INFO:   <<< n_display: 10
2023-12-22 21:37:22,930:INFO:   <<< n_gpu: 1
2023-12-22 21:37:22,930:INFO:   <<< n_pair: 1
2023-12-22 21:37:22,930:INFO:   <<< negative_weighting: 1
2023-12-22 21:37:22,930:INFO:   <<< num_thread_reader: 8
2023-12-22 21:37:22,930:INFO:   <<< output_dir: log
2023-12-22 21:37:22,930:INFO:   <<< precision: fp16
2023-12-22 21:37:22,930:INFO:   <<< pretrained_clip_name: ViT-B/32
2023-12-22 21:37:22,930:INFO:   <<< rank: 0
2023-12-22 21:37:22,930:INFO:   <<< rerank_coe_t: 1.0
2023-12-22 21:37:22,931:INFO:   <<< rerank_coe_v: 5.0
2023-12-22 21:37:22,931:INFO:   <<< resume_opt: None
2023-12-22 21:37:22,931:INFO:   <<< sampled_use_mil: False
2023-12-22 21:37:22,931:INFO:   <<< seed: 42
2023-12-22 21:37:22,931:INFO:   <<< sim_header: seqTransf
2023-12-22 21:37:22,931:INFO:   <<< slice_framepos: 2
2023-12-22 21:37:22,931:INFO:   <<< task_type: retrieval
2023-12-22 21:37:22,931:INFO:   <<< tau: 5
2023-12-22 21:37:22,931:INFO:   <<< text_num_hidden_layers: 12
2023-12-22 21:37:22,931:INFO:   <<< train_csv: data/.train.csv
2023-12-22 21:37:22,931:INFO:   <<< train_frame_order: 0
2023-12-22 21:37:22,931:INFO:   <<< use_mil: False
2023-12-22 21:37:22,931:INFO:   <<< val_csv: data/.val.csv
2023-12-22 21:37:22,931:INFO:   <<< video_dim: 1024
2023-12-22 21:37:22,931:INFO:   <<< visual_num_hidden_layers: 12
2023-12-22 21:37:22,931:INFO:   <<< warmup_proportion: 0.1
2023-12-22 21:37:22,931:INFO:   <<< world_size: 1
2023-12-22 21:37:22,932:INFO: device: cuda:0 n_gpu: 1
2023-12-22 21:37:25,575:INFO: loading archive file /home/lihao/PAU/modules/cross-base
2023-12-22 21:37:25,576:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2023-12-22 21:37:25,576:INFO: Weight doesn't exsits. /home/lihao/PAU/modules/cross-base/cross_pytorch_model.bin
2023-12-22 21:37:25,576:WARNING: Stage-One:True, Stage-Two:False
2023-12-22 21:37:25,576:WARNING: Test retrieval by loose type.
2023-12-22 21:37:25,576:WARNING: 	 embed_dim: 512
2023-12-22 21:37:25,576:WARNING: 	 image_resolution: 224
2023-12-22 21:37:25,576:WARNING: 	 vision_layers: 12
2023-12-22 21:37:25,576:WARNING: 	 vision_width: 768
2023-12-22 21:37:25,576:WARNING: 	 vision_patch_size: 32
2023-12-22 21:37:25,577:WARNING: 	 context_length: 77
2023-12-22 21:37:25,577:WARNING: 	 vocab_size: 49408
2023-12-22 21:37:25,577:WARNING: 	 transformer_width: 512
2023-12-22 21:37:25,577:WARNING: 	 transformer_heads: 8
2023-12-22 21:37:25,577:WARNING: 	 transformer_layers: 12
2023-12-22 21:37:25,577:WARNING: 		 linear_patch: 2d
2023-12-22 21:37:25,577:WARNING: 	 cut_top_layer: 0
2023-12-22 21:37:28,020:WARNING: 	 sim_header: seqTransf
2023-12-22 21:37:37,122:INFO: --------------------
2023-12-22 21:37:37,122:INFO: Weights of PAU not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
2023-12-22 21:37:37,122:INFO: Weights from pretrained model not used in PAU: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2023-12-22 21:37:38,069:INFO: ***** Running test *****
2023-12-22 21:37:38,069:INFO:   Num examples = 824
2023-12-22 21:37:38,069:INFO:   Batch size = 24
2023-12-22 21:37:38,069:INFO:   Num steps = 35
2023-12-22 21:37:38,070:INFO: ***** Running val *****
2023-12-22 21:37:38,070:INFO:   Num examples = 842
2023-12-22 21:42:31,514:INFO: sim matrix size: 824, 824
2023-12-22 21:42:31,533:INFO: 	 Length-T: 824, Length-V:824
2023-12-22 21:42:31,534:INFO: Text-to-Video:
2023-12-22 21:42:31,534:INFO: 	>>>  R@1: 48.4 - R@5: 75.9 - R@10: 84.3 - Median R: 2.0 - Mean R: 13.0
2023-12-22 21:42:31,534:INFO: Video-to-Text:
2023-12-22 21:42:31,534:INFO: 	>>>  V2T$R@1: 48.1 - V2T$R@5: 74.2 - V2T$R@10: 85.7 - V2T$Median R: 2.0 - V2T$Mean R: 9.8
